{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/costasmexis/pyenvs/main/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from machinelearning.mlpipeline import MLPipelines\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = LogisticRegression()\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "csv_dir = 'data/composite_dataset.csv'\n",
    "label = 'group'\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "mlpipe = MLPipelines(estimator=model, param_grid=param_grid, label=label, csv_dir=csv_dir)\n",
    "mlpipe.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-14 18:17:12,895] A new study created in memory with name: no-name-bbb63c57-de0b-4bb4-8d8a-d79a4fd6c7f9\n",
      "[W 2023-12-14 18:17:12,900] Trial 0 failed with parameters: {'n_estimators': 106, 'max_depth': 2, 'min_samples_leaf': 4, 'min_samples_split': 9, 'bootstrap': True} because of the following error: TypeError('sklearn.base.BaseEstimator.set_params() argument after ** must be a mapping, not RandomForestClassifier').\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/costasmexis/pyenvs/main/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/costasmexis/AI4META/machinelearning/mlestimator.py\", line 190, in objective\n",
      "    model = create_model(trial)\n",
      "  File \"/home/costasmexis/AI4META/machinelearning/mlestimator.py\", line 186, in create_model\n",
      "    model.set_params(**params)\n",
      "TypeError: sklearn.base.BaseEstimator.set_params() argument after ** must be a mapping, not RandomForestClassifier\n",
      "[W 2023-12-14 18:17:12,903] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "sklearn.base.BaseEstimator.set_params() argument after ** must be a mapping, not RandomForestClassifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmlpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbayesian_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AI4META/machinelearning/mlestimator.py:196\u001b[0m, in \u001b[0;36mMachineLearningEstimator.bayesian_search\u001b[0;34m(self, X, y, scoring, direction, n_trials)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    195\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39mdirection)\n\u001b[0;32m--> 196\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_score \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n",
      "File \u001b[0;32m~/pyenvs/main/lib/python3.10/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenvs/main/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/pyenvs/main/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/pyenvs/main/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/pyenvs/main/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m~/AI4META/machinelearning/mlestimator.py:190\u001b[0m, in \u001b[0;36mMachineLearningEstimator.bayesian_search.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjective\u001b[39m(trial):\n\u001b[0;32m--> 190\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m    192\u001b[0m     score \u001b[38;5;241m=\u001b[39m cross_val_score(model, X, y, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39mscoring)\n",
      "File \u001b[0;32m~/AI4META/machinelearning/mlestimator.py:186\u001b[0m, in \u001b[0;36mMachineLearningEstimator.bayesian_search.<locals>.create_model\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    184\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbayesian_grid[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname](trial)\n\u001b[1;32m    185\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavailable_clfs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname]\n\u001b[0;32m--> 186\u001b[0m model\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mTypeError\u001b[0m: sklearn.base.BaseEstimator.set_params() argument after ** must be a mapping, not RandomForestClassifier"
     ]
    }
   ],
   "source": [
    "mlpipe.bayesian_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpipe.bayesian_grid['SVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpipe.create_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = mlpipe.bootsrap(optimizer='random_search', \\\n",
    "    random_iter=3, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpipe.random_search(n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpipe.best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimization(MachineLearningEstimator):\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, \n",
    "                 estimator, param_grid, label, csv_dir,\n",
    "                 scoring='accuracy', direction='maximize'):\n",
    "        \n",
    "        super().__init__(estimator, param_grid, label, csv_dir)\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.scoring = scoring\n",
    "        self.direction = direction\n",
    "\n",
    "        if self.scoring not in sklearn.metrics.SCORERS.keys():\n",
    "            raise ValueError(f'Invalid scoring metric: {self.scoring}. Select one of the following: {list(sklearn.metrics.SCORERS.keys())}')\n",
    "\n",
    "        self.available_clf = {\n",
    "            'RandomForestClassifier': RandomForestClassifier,\n",
    "            'KNeighborsClassifier': KNeighborsClassifier,\n",
    "            'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "            'SVC': SVC,\n",
    "            'GradientBoostingClassifier': GradientBoostingClassifier\n",
    "        }\n",
    "\n",
    "        if self.estimator in self.available_clf.values():\n",
    "            raise ValueError(f'Invalid estimator: {self.estimator}. Select one of the following: {list(self.available_clf.keys())}')\n",
    "        \n",
    "        self.bayesian_clfs = {\n",
    "            'RandomForestClassifier': lambda trial: RandomForestClassifier(\n",
    "                n_estimators=trial.suggest_int('n_estimators', 2, 200),\n",
    "                criterion='gini',  # or trial.suggest_categorical('criterion', ['gini', 'entropy'])\n",
    "                max_depth=trial.suggest_int('max_depth', 1, 50),\n",
    "                min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                bootstrap=trial.suggest_categorical('bootstrap', [True, False]),\n",
    "                n_jobs=-1,\n",
    "            ),\n",
    "            'KNeighborsClassifier': lambda trial: KNeighborsClassifier(\n",
    "                n_neighbors=trial.suggest_int('n_neighbors', 2, 15),\n",
    "                weights=trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "                algorithm=trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
    "                p=trial.suggest_int('p', 1, 2),\n",
    "                leaf_size=trial.suggest_int('leaf_size', 5, 50),\n",
    "                n_jobs=-1\n",
    "            ),\n",
    "            'DecisionTreeClassifier': lambda trial: DecisionTreeClassifier(\n",
    "                trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "                splitter=trial.suggest_categorical('splitter', ['best', 'random']),\n",
    "                max_depth=trial.suggest_int('max_depth', 1, 100),\n",
    "                min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                min_weight_fraction_leaf=trial.suggest_float('min_weight_fraction_leaf', 0.0, 0.5),\n",
    "            ),\n",
    "            'SVC': lambda trial: SVC(\n",
    "                C=trial.suggest_int('C', 1, 10),\n",
    "                kernel=trial.suggest_categorical('kernel', ['linear', 'rbf', 'sigmoid']),\n",
    "                probability=trial.suggest_categorical('probability', [True, False]),\n",
    "                shrinking=trial.suggest_categorical('shrinking', [True, False]),\n",
    "                decision_function_shape=trial.suggest_categorical('decision_function_shape', ['ovo', 'ovr'])\n",
    "            ),\n",
    "            'GradientBoostingClassifier': lambda trial: GradientBoostingClassifier(\n",
    "                loss=trial.suggest_categorical('loss', ['log_loss', 'exponential']),\n",
    "                learning_rate=trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "                n_estimators=trial.suggest_int('n_estimators', 2, 200),\n",
    "                criterion=trial.suggest_categorical('criterion', ['friedman_mse', 'squared_error']),\n",
    "                max_depth=trial.suggest_int('max_depth', 1, 50),\n",
    "                min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "                min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            )\n",
    "    }\n",
    "\n",
    "    def create_model(self, trial):\n",
    "        if self.estimator.__class__.__name__ in self.bayesian_clfs.keys():\n",
    "            model = self.bayesian_clfs[self.estimator](trial)\n",
    "        else:\n",
    "            raise ValueError('Classifier not supported')\n",
    "        return model\n",
    "    \n",
    "    def objective(self, trial):\n",
    "        model = self.create_model(trial=trial)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        eval_metric = get_scorer(self.scoring)._score_func(self.y_test, y_pred)\n",
    "        return eval_metric\n",
    "\n",
    "    def run_optimization(self, n_trials=10):\n",
    "        self.clf = self.available_clf[self.estimator.__class__.__name__]\n",
    "\n",
    "        study = optuna.create_study(direction=self.direction)\n",
    "        study.optimize(self.objective, n_trials=n_trials)\n",
    "\n",
    "        if self.estimator.__class__.__name__ in self.bayesian_clfs:\n",
    "            self.model = self.available_clf[self.estimator.__class__.__name__](**study.best_params)\n",
    "        else:\n",
    "            raise ValueError('Classifier not supported')\n",
    "\n",
    "        return study\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from validation import boostrap, nested_cv\n",
    "from validation.bayesian_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'data/composite_dataset.csv'\n",
    "\n",
    "dataloader = DataLoader(label='group', csv_dir=PATH)\n",
    "dataloader.normalize(method='standard')\n",
    "dataloader.feature_selection(n_features=25)\n",
    "dataloader.encode_categorical()\n",
    "print(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "param_grid = {'penalty': ['l1'], 'C': [1, 10, 100, 200, 500], \n",
    "            'solver': ['liblinear'], 'max_iter': [10000]}\n",
    "lr_scores = boostrap(estimator=lr, X=dataloader.X, param_grid=param_grid, y=dataloader.y, scoring='mcc', n_iterations=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, nested_scores = nested_cv(lr, param_grid=param_grid, inner_scoring='matthews_corrcoef', outer_scoring='matthews_corrcoef', \n",
    "                               X=dataloader.X, y=dataloader.y, num_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(nested_scores)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Nested Cross Validation Scores')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "# list(sklearn.metrics.SCORERS.keys())\n",
    "lr.fit(dataloader.X, dataloader.y)\n",
    "y_pred = lr.predict(dataloader.X)\n",
    "y_true = dataloader.y\n",
    "\n",
    "from sklearn.metrics import get_scorer\n",
    "\n",
    "# Suppose you have a scorer key, for example, 'matthews_corrcoef'\n",
    "scorer_key = 'matthews_corrcoef'\n",
    "\n",
    "# Get the scorer object using the key\n",
    "scorer = get_scorer(scorer_key)\n",
    "\n",
    "# Now, if you have true labels y_true and predicted labels y_pred\n",
    "score = scorer._score_func(y_true, y_pred)  # Replace y_true and y_pred with your actual data\n",
    "\n",
    "print(\"Score using the scorer object:\", score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
